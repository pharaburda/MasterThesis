# -*- coding: utf-8 -*-
"""SynergicDeepModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e0E9Rrl_q4rMr7K5SuHBueH99Q46al4b
"""

import torch
import torchvision.models as models
from torch import nn, optim
import math
from torchvision import datasets
from torchvision.transforms import transforms
import os
from torchvision.utils import save_image
import torch.utils.data
import torch.nn.functional as F
from PIL import Image
import time
import re
import numpy as np
import matplotlib.pyplot as plt

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
num_classes = 4

class SynergicNet(nn.Module):
    def __init__(self):
      super(SynergicNet, self).__init__()
      self.fc1 = nn.Linear(4096, 1024)
      self.fc2 = nn.Linear(1024, 256)
      self.fc3 = nn.Linear(256, 2)

    def forward(self, first, second):
      x = torch.cat((first, second), 1).unsqueeze(1)
      x = torch.flatten(x, 1)
      x = self.fc1(x)
      x = self.fc2(x)
      x = self.fc3(x)
      output = F.softmax(x, dim=1)
      return output


def initialize_model(device, use_pretrained=True):
    model_1 = None
    model_2 = None
    torch.manual_seed(10)

    model_1 = models.resnet50(pretrained=use_pretrained)#.to(device)
    model_2 = models.resnet50(pretrained=use_pretrained)#.to(device)

    num_ftrs = model_1.fc.in_features
    model_1.fc = nn.Linear(num_ftrs, num_classes)

    num_ftrs = model_2.fc.in_features
    model_2.fc = nn.Linear(num_ftrs, num_classes)

    model_s = SynergicNet()#.to(device)
    return model_1, model_2, model_s

def save_checkpoint(epoch, model_c1, model_c2, model_cs, optimizer_c1,
                    optimizer_c2, optimizer_cs):
    path = "drive/My Drive/checkpoint.pt"
    torch.save({
            'epoch': epoch,
            'first_component_state_dict': model_c1.state_dict(),
            'second_component_state_dict': model_c2.state_dict(),
            'synergic_component_state_dict': model_cs.state_dict(),
            'optimizer_1_state_dict': optimizer_c1.state_dict(),
            'optimizer_2_state_dict': optimizer_c2.state_dict(),
            'optimizer_S_state_dict': optimizer_cs.state_dict()
            }, path)
    
def load_checkpoint(model_c1, model_c2, model_cs, optimizer_c1, optimizer_c2,
                    optimizer_cs):
    path = "drive/My Drive/checkpoint.pt"
    checkpoint = torch.load(path)
    epoch = checkpoint['epoch']
    model_c1.load_state_dict(checkpoint['first_component_state_dict'])
    model_c2.load_state_dict(checkpoint['second_component_state_dict'])
    model_cs.load_state_dict(checkpoint['synergic_component_state_dict'])
    optimizer_c1.load_state_dict(checkpoint['optimizer_1_state_dict'])
    optimizer_c2.load_state_dict(checkpoint['optimizer_2_state_dict'])
    optimizer_cs.load_state_dict(checkpoint['optimizer_S_state_dict'])

    return epoch

def train_model(device, model_c1, model_c2, model_cs, dataloader_c1, dataloader_c2, 
                optimizer_c1, optimizer_c2, optimizer_cs,
                criterion_c1, criterion_c2, criterion_cs, num_epochs = 7,
                use_checkpoint = False):
    since = time.time()
    start_epoch = 0
    if (use_checkpoint):
        start_epoch = load_checkpoint(model_c1, model_c2, model_cs, optimizer_c1,
                                      optimizer_c2, optimizer_cs) + 1
    
    best_acc_1 = 0.0
    best_acc_2 = 0.0
    best_acc_s = 0.0

    for epoch in range(start_epoch, num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model_c1.train()
                model_c2.train()
                model_cs.train()
                
            else:
                model_c1.eval()
                model_c2.eval()
                model_cs.eval()
            
            running_loss_c1 = 0.0
            running_corrects_c1 = 0
            running_loss_c2 = 0.0
            running_corrects_c2 = 0
            running_loss_s = 0.0
            running_corrects_s = 0

            for (input_c1, label_c1), (input_c2, label_c2) in zip(dataloader_c1[phase], dataloader_c2[phase]):
                input_c1 = input_c1.to(device)
                label_c1 = label_c1.to(device)
                input_c2 = input_c2.to(device)
                label_c2 = label_c2.to(device)

                optimizer_c1.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    outputs_c1 = model_c1(input_c1)
                    #labels_c1_2d = label_c1.repeat(1,num_classes)
                    loss_c1 = criterion_c1(outputs_c1, label_c1)

                    _, preds_c1 = torch.max(outputs_c1, 1)

                    if phase == 'train':
                        loss_c1.backward()
                        optimizer_c1.step()
                  
                running_loss_c1 += loss_c1.item() #* input_c1.size(0)
                running_corrects_c1 += torch.sum(preds_c1 == label_c1.data)
                  
                optimizer_c2.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    outputs_c2 = model_c2(input_c2)
                    #labels_c2_2d = label_c2.repeat(1,num_classes)
                    loss_c2 = criterion_c2(outputs_c2, label_c2)

                    _, preds_c2 = torch.max(outputs_c2, 1)

                    if phase == 'train':
                        loss_c2.backward()
                        optimizer_c2.step()

                running_loss_c2 += loss_c2.item() #* input_c2.size(0)
                running_corrects_c2 += torch.sum(preds_c2 == label_c2.data)

                optimizerS.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    f_extract_c1 = torch.nn.Sequential(*list(model_c1.children())[:-1])
                    f_extract_c2 = torch.nn.Sequential(*list(model_c2.children())[:-1])
                    out_1 = f_extract_c1(input_c1)
                    out_2 = f_extract_c2(input_c2)
                
                    output = model_cs(out_1, out_2)
                    label = 1 if label_c1==label_c2 else 0
                    label = torch.LongTensor([label]).to(device)

                    lossS = criterion_cs(output, label)

                    _, preds_s = torch.max(output, 1)

                    if phase == 'train':
                        lossS.backward()
                        optimizerS.step()
               
                running_loss_s += lossS.item() #* (input_c1.size(0) + input_c2.size(0)) 
                running_corrects_s += torch.sum(preds_s == label.data)

            calculations_count = len(dataloader_c1[phase].dataset)

            epoch_loss = running_loss_c1 / calculations_count
            epoch_acc = running_corrects_c1.double() / calculations_count

            epoch_loss_2 = running_loss_c2 / calculations_count
            epoch_acc_2 = running_corrects_c2.double() / calculations_count

            epoch_loss_s = running_loss_s / calculations_count
            epoch_acc_s = running_corrects_s.double() / calculations_count

            print('{} First component loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))
            print('{} Second component loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss_2, epoch_acc_2))
            print('{} Synergic component loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss_s, epoch_acc_s))

            save_checkpoint(epoch, model_c1, model_c2, model_cs, optimizer_c1,
                    optimizer_c2, optimizer_cs)
            if phase == 'val' and epoch_acc > best_acc_1:
              best_acc_1 = epoch_acc

            if phase == 'val' and epoch_acc_2 > best_acc_2:
              best_acc_2 = epoch_acc_2
            
            if phase == 'val' and epoch_acc_s > best_acc_s:
              best_acc_s = epoch_acc_s

    print()
    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Besc scores: first component {:.4f}, second component {:.4f} , synergic component {:.4f}'.format(best_acc_1, best_acc_2, best_acc_s))

class RandomMask(object):
    """Replaces black pixels with random ones."""

    def __call__(self, image):
      h = image.size[0]
      w = image.size[1]
      pixels = image.load()

      for y in range(0, h):
          for x in range(0, w):
              if (pixels[y,x]==(0,0,0)):
                r = np.random.randint(low = 0, high = 255)
                g = np.random.randint(low = 0, high = 255)
                b = np.random.randint(low = 0, high = 255)
                image.putpixel((y, x),(r, g, b))
      return image

data_dir = '/content/drive/My Drive/magisterka'
class_count = {"train": 472, "val": 64}
input_size = (224, 224)
transform = transforms.Compose([
        transforms.Resize(input_size),
        RandomMask(),
        transforms.ToTensor(),
        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])
    ])

image_dataset = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform) for x in ['train', 'val']}
#print(image_dataset['train'][0][0])
#image_dataset['train'][0][0].save('image.jpg')

imageloader_c1 = {x: torch.utils.data.DataLoader(image_dataset[x], shuffle=True, num_workers=8) for x in ['train', 'val']}
imageloader_c2 = {x: torch.utils.data.DataLoader(image_dataset[x], shuffle=True, num_workers=8) for x in ['train', 'val']}

model_c1, model_c2, model_cs = initialize_model(device)
model_c1 = model_c1.to(device)
model_c2 = model_c2.to(device)
model_cs = model_cs.to(device)

params_to_update = []
for param in model_c1.parameters():
  params_to_update.append(param)
for param in model_c2.parameters():
  params_to_update.append(param)
for param in model_cs.parameters():
  params_to_update.append(param)

optimizer1 = optim.SGD(model_c1.parameters(), lr=0.0003, momentum=0.9)
optimizer2 = optim.SGD(model_c2.parameters(), lr=0.0003, momentum=0.9)
optimizerS = optim.SGD(params_to_update, lr=0.0003, momentum=0.9)

criterion_c1 = nn.CrossEntropyLoss()
criterion_c2 = nn.CrossEntropyLoss()
synergic_criterion = nn.HingeEmbeddingLoss()

output = train_model(device, model_c1, model_c2, model_cs, imageloader_c1, imageloader_c2,
                     optimizer1,optimizer2,optimizerS, criterion_c1, criterion_c2,
                     synergic_criterion, num_epochs = 3, use_checkpoint = False)

!pip install dask

!pip install graphviz

!pip install toolz

from graphviz import Digraph
import torch
from torch.autograd import Variable

def make_dot(var, params=None):
    """ Produces Graphviz representation of PyTorch autograd graph
    Blue nodes are the Variables that require grad, orange are Tensors
    saved for backward in torch.autograd.Function
    Args:
        var: output Variable
        params: dict of (name, Variable) to add names to node that
            require grad (TODO: make optional)
    """
    if params is not None:
        assert isinstance(params.values()[0], Variable)
        param_map = {id(v): k for k, v in params.items()}

    node_attr = dict(style='filled',
                     shape='box',
                     align='left',
                     fontsize='12',
                     ranksep='0.1',
                     height='0.2')
    dot = Digraph(node_attr=node_attr, graph_attr=dict(size="12,12"))
    seen = set()

    def size_to_str(size):
        return '('+(', ').join(['%d' % v for v in size])+')'

    def add_nodes(var):
        if var not in seen:
            if torch.is_tensor(var):
                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')
            elif hasattr(var, 'variable'):
                u = var.variable
                name = param_map[id(u)] if params is not None else ''
                node_name = '%s\n %s' % (name, size_to_str(u.size()))
                dot.node(str(id(var)), node_name, fillcolor='lightblue')
            else:
                dot.node(str(id(var)), str(type(var).__name__))
            seen.add(var)
            if hasattr(var, 'next_functions'):
                for u in var.next_functions:
                    if u[0] is not None:
                        dot.edge(str(id(u[0])), str(id(var)))
                        add_nodes(u[0])
            if hasattr(var, 'saved_tensors'):
                for t in var.saved_tensors:
                    dot.edge(str(id(t)), str(id(var)))
                    add_nodes(t)
    add_nodes(var.grad_fn)
    return dot

make_dot(output).view()

data_dir = '/content/drive/My Drive/magisterka/val'
output_dir = data_dir + '/normal/'
NORMAL = 3
GLAUCOMA = 2
AMD = 0
DR = 1
flip_suffix = '_flip.jpg'
rotated_suffix = '_rotated.jpg'

input_size = (224, 224)
transform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.ToTensor()
    ])
flipTransform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.RandomHorizontalFlip(p=1),
        transforms.ToTensor()
    ])

rotationTransform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.RandomRotation(degrees=10, resample=Image.BICUBIC),
        transforms.ToTensor()
    ])

cropTransform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0), ratio=(1.0, 1.2)),
        transforms.ToTensor()
    ])

normalizeTransform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
        transforms.ToTensor()
    ])

def save_transformed_image():
  image_dataset = datasets.ImageFolder(os.path.join(data_dir), rotationTransform)
  for file_path, file_class in image_dataset.imgs:
  #print(file_path, file_class)
  if file_class == NORMAL:
    file_name = os.path.splitext(os.path.basename(file_path))[0]
    idx = image_dataset.imgs.index((file_path, file_class))
    save_image(image_dataset[idx][0], output_dir + file_name + rotated_suffix)


image_dataset = datasets.ImageFolder(os.path.join(data_dir), rotationTransform)

import cv2

src1 = cv2.imread('/content/drive/My Drive/random images/random image 1.jpg')
src2 = cv2.imread('/content/drive/My Drive/random images/random image 2.jpg')
src3 = cv2.imread('/content/drive/My Drive/random images/random image 3.jpg')
src4 = cv2.imread('/content/drive/My Drive/random images/random image 4.jpg')
src5 = cv2.imread('/content/drive/My Drive/random images/random image.jpeg')

src1 = cv2.resize(src1, (224,224))
src2 = cv2.resize(src2, (224,224))
src3 = cv2.resize(src3, (224,224))
src4 = cv2.resize(src4, (224,224))
src5 = cv2.resize(src5, (224,224))

dst1 = cv2.addWeighted(src1, 0.5, src2, 0.5, 0)
dst2 = cv2.addWeighted(src3, 0.5, src4, 0.5, 0)
dst3 = cv2.addWeighted(dst1, 0.5, dst2, 0.5, 0)
dst4 = cv2.addWeighted(dst3, 0.5, src5, 0.5, 0)

cv2.imwrite('mixed image.jpg', dst4)

import cv2
import numpy as np

image = cv2.imread('/content/drive/My Drive/magisterka/train/normal/01_h.jpg') 

image = cv2.resize(image, (224, 224)) 

h = image.shape[0]
w = image.shape[1]

for y in range(0, h):
    for x in range(0, w):
        if (image[y,x]==[0,0,0]).all():
          r = np.random.randint(low = 0, high = 255)
          g = np.random.randint(low = 0, high = 255)
          b = np.random.randint(low = 0, high = 255)
          image[y, x] = (r, g, b)

cv2.imwrite('output.jpg', image)

import os

phase = 'val'
 
glaucoma_dir = '/content/drive/My Drive/magisterka/' + phase + '/glaucoma'
glaucoma_len= len([name for name in os.listdir(glaucoma_dir) if os.path.isfile(os.path.join(glaucoma_dir, name))])
glaucoma_list = ['glaucoma'] * glaucoma_len
print(glaucoma_len) 

retinopathy_dir = '/content/drive/My Drive/magisterka/' + phase + '/diabetic retinopathy'
retinopathy_len= len([name for name in os.listdir(retinopathy_dir) if os.path.isfile(os.path.join(retinopathy_dir, name))])
retinopathy_list = ['dr'] * retinopathy_len
print(retinopathy_len) 

amd_dir = '/content/drive/My Drive/magisterka/' + phase + '/amd'
amd_len= len([name for name in os.listdir(amd_dir) if os.path.isfile(os.path.join(amd_dir, name))])
amd_list = ['amd'] * amd_len
print(amd_len) 

normal_dir = '/content/drive/My Drive/magisterka/' + phase + '/normal'
normal_len= len([name for name in os.listdir(normal_dir) if os.path.isfile(os.path.join(normal_dir, name))])
normal_list = ['normal'] * normal_len
print(normal_len)

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

def get_label_for_class(disease_class):
   return {
        0: 'amd',
        1: 'dr',
        2: 'glaucoma',
        3: 'normal'
    }[disease_class]

y_test = np.concatenate([amd_list, retinopathy_list, glaucoma_list, normal_list])

image_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform)

train_dataset = torch.utils.data.DataLoader(
        image_dataset, shuffle=False, num_workers=8
    )

model_c2.eval()
y_pred = []

for data, target in train_dataset:
  data = data.to(device)
  out = model_c2(data)
  _, preds_s = torch.max(out, 1)
  
  disease_class = preds_s.cpu().numpy()[0]
  y_pred.append(get_label_for_class(disease_class))


print(classification_report(y_pred, y_test))

labels = ['amd', 'dr', 'glaucoma', 'normal']
matrix = confusion_matrix(y_test, y_pred)
print(matrix)

ax= plt.subplot()
sns.heatmap(matrix, annot=True, ax=ax)

ax.set_xlabel('Predicted')
ax.set_ylabel('True')
ax.xaxis.set_ticklabels(labels)
ax.yaxis.set_ticklabels(labels)
plt.savefig('confusion matrix')

import cv2
import numpy as np
import torch
from torchvision import models

class FeatureExtractor():
    """ Class for extracting activations and
    registering gradients from targetted intermediate layers """

    def __init__(self, model, target_layers):
        self.model = model
        self.target_layers = target_layers
        self.gradients = []

    def save_gradient(self, grad):
        self.gradients.append(grad)

    def __call__(self, x):
        outputs = []
        self.gradients = []
        for name, module in self.model._modules.items():
            x = module(x)
            if name in self.target_layers:
                x.register_hook(self.save_gradient)
                outputs += [x]
        return outputs, x


class ModelOutputs():
    """ Class for making a forward pass, and getting:
    1. The network output.
    2. Activations from intermeddiate targetted layers.
    3. Gradients from intermeddiate targetted layers. """

    def __init__(self, model, feature_module, target_layers):
        self.model = model
        self.feature_module = feature_module
        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)

    def get_gradients(self):
        return self.feature_extractor.gradients

    def __call__(self, x):
        target_activations = []
        for name, module in self.model._modules.items():
            if module == self.feature_module:
                target_activations, x = self.feature_extractor(x)
            elif "avgpool" in name.lower():
                x = module(x)
                x = x.view(x.size(0),-1)
            else:
                x = module(x)

        return target_activations, x


def preprocess_image(img):
    means = [0.485, 0.456, 0.406]
    stds = [0.229, 0.224, 0.225]

    preprocessed_img = img.copy()[:, :, ::-1]
    for i in range(3):
        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]
        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]
    preprocessed_img = \
        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))
    preprocessed_img = torch.from_numpy(preprocessed_img)
    preprocessed_img.unsqueeze_(0)
    input = preprocessed_img.requires_grad_(True)
    return input


def show_cam_on_image(img, mask):
    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)
    heatmap = np.float32(heatmap) / 255
    cam = heatmap + np.float32(img)
    cam = cam / np.max(cam)
    cv2.imwrite("cam.jpg", np.uint8(255 * cam))


class GradCam:
    def __init__(self, model, feature_module, target_layer_names, use_cuda):
        self.model = model
        self.feature_module = feature_module
        self.model.eval()
        self.cuda = use_cuda
        if self.cuda:
            self.model = model.cuda()

        self.extractor = ModelOutputs(self.model, self.feature_module, target_layer_names)

    def forward(self, input):
        return self.model(input)

    def __call__(self, input, index=None):
        if self.cuda:
            features, output = self.extractor(input.cuda())
        else:
            features, output = self.extractor(input)

        if index == None:
            index = np.argmax(output.cpu().data.numpy())

        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)
        one_hot[0][index] = 1
        one_hot = torch.from_numpy(one_hot).requires_grad_(True)
        if self.cuda:
            one_hot = torch.sum(one_hot.cuda() * output)
        else:
            one_hot = torch.sum(one_hot * output)

        self.feature_module.zero_grad()
        self.model.zero_grad()
        one_hot.backward(retain_graph=True)

        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()

        target = features[-1]
        target = target.cpu().data.numpy()[0, :]

        weights = np.mean(grads_val, axis=(2, 3))[0, :]
        cam = np.zeros(target.shape[1:], dtype=np.float32)

        for i, w in enumerate(weights):
            cam += w * target[i, :, :]

        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, input.shape[2:])
        cam = cam - np.min(cam)
        cam = cam / np.max(cam)
        return cam

def deprocess_image(img):
    """ see https://github.com/jacobgil/keras-grad-cam/blob/master/grad-cam.py#L65 """
    img = img - np.mean(img)
    img = img / (np.std(img) + 1e-5)
    img = img * 0.1
    img = img + 0.5
    img = np.clip(img, 0, 1)
    return np.uint8(img*255)

#image_path = '/content/drive/My Drive/magisterka/val/glaucoma/glaucomaimage40prime_flip.jpg'
#image_path = '/content/drive/My Drive/magisterka/val/amd/aria_d_17_12.tif'
#image_path = '/content/drive/My Drive/magisterka/val/diabetic retinopathy/IDRiD_413_flip.jpg'
image_path = '/content/drive/My Drive/magisterka/val/normal/im0253.jpg'

grad_cam = GradCam(model=model_c2, feature_module=model_c2.layer4, target_layer_names=["2"], use_cuda=True)

img = cv2.imread(image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = np.float32(cv2.resize(img, (224, 224))) / 255
input = preprocess_image(img)

# If None, returns the map for the highest scoring category.
# Otherwise, targets the requested index.
target_index = None
mask = grad_cam(input, target_index)

show_cam_on_image(img, mask)